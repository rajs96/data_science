{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some modules we may need first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the occupancy data we are going to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.250000</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.500000</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.250000</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.500000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-02-04 17:55:59</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>419.0</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-02-04 17:57:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>419.0</td>\n",
       "      <td>701.666667</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light         CO2  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.250000   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.000000   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.500000   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.250000   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.500000   \n",
       "6  2015-02-04 17:55:59        23.10   27.2000  419.0  701.000000   \n",
       "7  2015-02-04 17:57:00        23.10   27.2000  419.0  701.666667   \n",
       "\n",
       "   HumidityRatio  Occupancy  \n",
       "1       0.004793          1  \n",
       "2       0.004783          1  \n",
       "3       0.004779          1  \n",
       "4       0.004772          1  \n",
       "5       0.004757          1  \n",
       "6       0.004757          1  \n",
       "7       0.004757          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../data/occupancy_data/datatraining.txt'\n",
    "df_training = pd.read_csv(filename)\n",
    "# inspect the data\n",
    "df_training.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8143 entries, 1 to 8143\n",
      "Data columns (total 7 columns):\n",
      "date             8143 non-null object\n",
      "Temperature      8143 non-null float64\n",
      "Humidity         8143 non-null float64\n",
      "Light            8143 non-null float64\n",
      "CO2              8143 non-null float64\n",
      "HumidityRatio    8143 non-null float64\n",
      "Occupancy        8143 non-null int64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 508.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_training.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like we have any null entries, so we don't have to do any imputing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan is to implement logistic regression from scratch, and see how well that performs against sklearn's logistic regression. Let's put our data into numpy arrays, splitting our training set into our X variable and the Y variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the datetime column\n",
    "X_train = df_training.iloc[:,1:6].values\n",
    "y_train = df_training['Occupancy'].values\n",
    "# now, we need to add a column of 1's to the front of the X so we can take into account\n",
    "# the intercept term\n",
    "ones = np.ones((8143,1))\n",
    "Xb_train = np.concatenate((ones,X_train),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the logistic function and perform our gradient descent. We will do this by taking the derivative of the cross-entropy error function and continually updating our weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weights:', array([-4.50498652e+03, -9.34492166e+04, -8.00111640e+04,  1.50908672e+04,\n",
      "        1.04046475e+03, -1.34030311e+01]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajsingh/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(6) # initialize weights randomly, need an extra weight for intercept term\n",
    "def sigmoid(z):\n",
    "    return 1./(1.+np.exp(-z))\n",
    "y_pred = sigmoid(Xb_train.dot(W)) # initial prediction is based on random weights\n",
    "learning_rate = 0.01\n",
    "# we will perform 1000 iterations\n",
    "for i in range(0,1000):\n",
    "    W-= learning_rate * Xb_train.T.dot(y_pred-y_train) # update weight based on derivative\n",
    "    y_pred = sigmoid(Xb_train.dot(W))\n",
    "print(\"weights:\",W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these weights to what we would get from running the sklearn Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.16482752e-01,  4.40977352e-02,  1.99510758e-02,\n",
       "         4.31632201e-03, -3.47110769e-05]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the logistic regression model from sklearn outputs a model with very different weights: this is probably because sklearn optimizes the weights using regularization, and we simply did this using regularization. Let's test the accuracy of the model in both cases by using the test set that was calculated by the ML Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2665 entries, 140 to 2804\n",
      "Data columns (total 7 columns):\n",
      "date             2665 non-null object\n",
      "Temperature      2665 non-null float64\n",
      "Humidity         2665 non-null float64\n",
      "Light            2665 non-null float64\n",
      "CO2              2665 non-null float64\n",
      "HumidityRatio    2665 non-null float64\n",
      "Occupancy        2665 non-null int64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 166.6+ KB\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/occupancy_data/datatest.txt'\n",
    "df_test = pd.read_csv(filename)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the datetime column\n",
    "X_test = df_test.iloc[:,1:6].values\n",
    "y_test = df_test['Occupancy'].values\n",
    "# now, we need to add a column of 1's to the front of the X so we can take into account\n",
    "# the intercept term\n",
    "ones = np.ones((2665,1))\n",
    "Xb_test = np.concatenate((ones,X_test),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure how accurate our gradient descent model was on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy was 0.9789868667917448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajsingh/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "y_pred_GD = np.round(sigmoid(Xb_test.dot(W))) # round to 0 or 1 based on 0.5 threshold\n",
    "accuracy = np.sum(y_pred_GD==y_test)/float(len(y_test))\n",
    "print(\"The accuracy was \" + `accuracy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our model using gradient descent from scratch was very accurate. Let's see how well our sklearn model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782363977485928"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sk = logreg.predict(X_test)\n",
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our accuracy with the sklearn algorithm was actually lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
