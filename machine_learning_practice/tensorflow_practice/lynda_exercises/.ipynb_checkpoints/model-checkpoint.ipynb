{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajsingh/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"sales_data_training.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_training = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y_training = training_data_df[['total_earnings']].values\n",
    "\n",
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"sales_data_test.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_testing = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_testing = test_data_df[['total_earnings']].values\n",
    "\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9 input variables, and will create a 3-layer neural network with 50 nodes, 100 nodes, and 50 nodes respectively. We are trying to predict the 'total earnings' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.21781875, 0.23126331)\n",
      "(5, 0.028943483, 0.03147338)\n",
      "(10, 0.04032844, 0.041138917)\n",
      "(15, 0.022949705, 0.023837551)\n",
      "(20, 0.013487322, 0.014731992)\n",
      "(25, 0.013733491, 0.014897444)\n",
      "(30, 0.0103747165, 0.0111595355)\n",
      "(35, 0.0075028106, 0.008038129)\n",
      "(40, 0.0070414725, 0.0075469483)\n",
      "(45, 0.005451291, 0.005968302)\n",
      "(50, 0.004533495, 0.005026658)\n",
      "(55, 0.0038065643, 0.0042511933)\n",
      "(60, 0.0029724974, 0.0033567292)\n",
      "(65, 0.0024093052, 0.002758203)\n",
      "(70, 0.0019117111, 0.0022243294)\n",
      "(75, 0.0015029416, 0.0017614645)\n",
      "(80, 0.0012466385, 0.0014402182)\n",
      "(85, 0.0010537746, 0.0011755807)\n",
      "(90, 0.00086624315, 0.0009996642)\n",
      "(95, 0.000723104, 0.00085591554)\n",
      "training complete\n",
      "Final Training cost: 0.000636415032204\n",
      "Final Testing cost: 0.00074935820885\n"
     ]
    }
   ],
   "source": [
    "# define model parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "display_step = 5\n",
    "\n",
    "# define number of inputs and outputs\n",
    "number_of_inputs = 9\n",
    "number_of_outputs = 1\n",
    "\n",
    "# define how many neurons we want in each layer of the network\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "\n",
    "\n",
    "\n",
    "# Define layers\n",
    "\n",
    "# input layer \n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32,shape=(None,number_of_inputs))\n",
    "    \n",
    "# layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable('weights1',shape=[number_of_inputs,layer_1_nodes],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases1',shape=[layer_1_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X,weights)+biases)\n",
    "# layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable('weights2',shape=[layer_1_nodes,layer_2_nodes],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases2',shape=[layer_2_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output,weights)+biases)\n",
    "# layer 3    \n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable('weights3',shape=[layer_2_nodes,layer_3_nodes],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases3',shape=[layer_3_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output,weights)+biases)\n",
    "# output layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable('weights4',shape=[layer_3_nodes,number_of_outputs],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases4',shape=[number_of_outputs],initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output,weights)+biases\n",
    "    \n",
    "# define cost function\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction,Y))\n",
    "    \n",
    "# define optimizer\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# initialize session\n",
    "with tf.Session() as session:\n",
    "    # initializes all variables \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        # do one round of training\n",
    "        session.run(optimizer,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "        \n",
    "        # log training progress every 5 steps\n",
    "        if epoch % 5 ==0:\n",
    "            training_cost = session.run(cost,feed_dict={X:X_scaled_training, Y:Y_scaled_training})\n",
    "            testing_cost = session.run(cost,feed_dict={X:X_scaled_testing,Y:Y_scaled_testing})\n",
    "            print(epoch,training_cost,testing_cost)\n",
    "            \n",
    "    print(\"training complete\")\n",
    "    \n",
    "    final_training_cost = session.run(cost,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "    final_testing_cost = session.run(cost,feed_dict={X:X_scaled_testing,Y:Y_scaled_testing})\n",
    "    \n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
